{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class KNN:\n",
    "    def __init__(self, k=3, distance_metric='euclidean'):\n",
    "        self.k = k\n",
    "        self.distance_metric = distance_metric\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Store the training data as NumPy arrays\n",
    "        self.X_train = np.array(X)\n",
    "        self.y_train = np.array(y, dtype=int)  # Ensure y_train is integer type\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Predict the label for each example in the test set using vectorized operations\n",
    "        predictions = [self._predict(x) for x in np.array(X)]\n",
    "        return np.array(predictions)\n",
    "\n",
    "    def _predict(self, x):\n",
    "        # Compute the distances between x and all examples in the training set\n",
    "        distances = self.compute_distances(x, self.X_train)\n",
    "        \n",
    "        # Sort by distance and return the indices of the k nearest neighbors\n",
    "        k_indices = np.argsort(distances)[:self.k]\n",
    "        \n",
    "        # Get the labels of the k nearest samples\n",
    "        k_nearest_labels = self.y_train[k_indices]\n",
    "        \n",
    "        # Return the most common class among the k neighbors\n",
    "        return np.bincount(k_nearest_labels).argmax()\n",
    "\n",
    "    def compute_distances(self, x, X_train):\n",
    "        \"\"\" Efficient vectorized distance computation. \"\"\"\n",
    "        if self.distance_metric == 'euclidean':\n",
    "            # Vectorized Euclidean distance computation\n",
    "            return np.sqrt(np.sum((X_train - x) ** 2, axis=1))\n",
    "        elif self.distance_metric == 'manhattan':\n",
    "            # Vectorized Manhattan distance computation\n",
    "            return np.sum(np.abs(X_train - x), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def z_score_scaler(X, mean=None, std=None):\n",
    "    \"\"\" Scale features using z-score normalization. \"\"\"\n",
    "    if mean is None:\n",
    "        mean = np.mean(X, axis=0)\n",
    "    if std is None:\n",
    "        std = np.std(X, axis=0)\n",
    "    return (X - mean) / std, mean, std\n",
    "\n",
    "def one_hot_encode(df, column):\n",
    "    \"\"\" One-hot encode a single categorical column. \"\"\"\n",
    "    dummies = pd.get_dummies(df[column], prefix=column, drop_first=True)\n",
    "    df = pd.concat([df, dummies], axis=1)\n",
    "    df.drop(column, axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "def preprocess_data(train_path, test_path):\n",
    "    \"\"\" Preprocess the train and test datasets according to the task requirements. \"\"\"\n",
    "    \n",
    "    # Load the datasets\n",
    "    train_data = pd.read_csv(train_path)\n",
    "    test_data = pd.read_csv(test_path)\n",
    "    \n",
    "    # Drop irrelevant columns (CustomerId, Surname, id)\n",
    "    train_data = train_data.drop(columns=[\"CustomerId\", \"Surname\", \"id\"])\n",
    "    test_data = test_data.drop(columns=[\"CustomerId\", \"Surname\", \"id\"])\n",
    "    \n",
    "    # Handle missing values for numerical columns (fill with median)\n",
    "    # Selecting only numerical columns for missing value imputation\n",
    "    numeric_columns_train = train_data.select_dtypes(include=[np.number]).columns.drop(\"Exited\")\n",
    "    numeric_columns_test = test_data.select_dtypes(include=[np.number]).columns\n",
    "    \n",
    "    # Fill missing values with median for numeric columns\n",
    "    train_data[numeric_columns_train] = train_data[numeric_columns_train].fillna(train_data[numeric_columns_train].median())\n",
    "    test_data[numeric_columns_test] = test_data[numeric_columns_test].fillna(test_data[numeric_columns_test].median())\n",
    "    \n",
    "    # One-hot encode categorical variables (Geography, Gender) for both train and test data\n",
    "    train_data = one_hot_encode(train_data, \"Geography\")\n",
    "    train_data = one_hot_encode(train_data, \"Gender\")\n",
    "    \n",
    "    test_data = one_hot_encode(test_data, \"Geography\")\n",
    "    test_data = one_hot_encode(test_data, \"Gender\")\n",
    "    \n",
    "    # Align test_data with train_data columns by using column names (excluding 'Exited')\n",
    "    # We don't want to use row indices for reindexing columns, so we use train_data's columns except for 'Exited'.\n",
    "    test_data = test_data.reindex(columns=train_data.drop(columns=[\"Exited\"]).columns, fill_value=0)\n",
    "    \n",
    "    # Separate features (X) and target (y) for training data\n",
    "    X_train = train_data.drop(columns=[\"Exited\"])  # Training features\n",
    "    y_train = train_data[\"Exited\"]\n",
    "    \n",
    "    # Scale the features using z-score normalization (fit on train, transform on both train and test)\n",
    "    X_train_scaled, mean_train, std_train = z_score_scaler(X_train)\n",
    "    X_test_scaled, _, _ = z_score_scaler(test_data, mean_train, std_train)\n",
    "    \n",
    "    return X_train_scaled, y_train, X_test_scaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def cross_validate(X, y, knn, n_splits=5):\n",
    "    # Shuffle and split the data into k folds\n",
    "    indices = np.arange(X.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    fold_size = X.shape[0] // n_splits\n",
    "    folds = [indices[i * fold_size: (i + 1) * fold_size] for i in range(n_splits)]\n",
    "    \n",
    "    accuracy_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    f1_scores = []\n",
    "    roc_auc_scores = []\n",
    "    \n",
    "    # Cross-validation loop\n",
    "    for i in range(n_splits):\n",
    "        # Create training and validation sets\n",
    "        val_indices = folds[i]\n",
    "        train_indices = np.concatenate([folds[j] for j in range(n_splits) if j != i])\n",
    "        \n",
    "        # Use .iloc[] to access rows by index for DataFrames\n",
    "        X_train, X_val = X.iloc[train_indices], X.iloc[val_indices]\n",
    "        y_train, y_val = y.iloc[train_indices], y.iloc[val_indices]\n",
    "        \n",
    "        # Train the KNN model on the training set\n",
    "        knn.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict on the validation set\n",
    "        y_pred = knn.predict(X_val)\n",
    "        \n",
    "        # Calculate evaluation metrics\n",
    "        accuracy_scores.append(accuracy_score(y_val, y_pred))\n",
    "        precision_scores.append(precision_score(y_val, y_pred))\n",
    "        recall_scores.append(recall_score(y_val, y_pred))\n",
    "        f1_scores.append(f1_score(y_val, y_pred))\n",
    "        roc_auc_scores.append(roc_auc_score(y_val, y_pred))\n",
    "    \n",
    "    # Return the average of each metric across the folds\n",
    "    return {\n",
    "        'accuracy': np.mean(accuracy_scores),\n",
    "        'precision': np.mean(precision_scores),\n",
    "        'recall': np.mean(recall_scores),\n",
    "        'f1': np.mean(f1_scores),\n",
    "        'roc_auc': np.mean(roc_auc_scores)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Scores for k=3, distance_metric=euclidean: {'accuracy': np.float64(0.8664), 'precision': np.float64(0.7043418396079192), 'recall': np.float64(0.5851451243868693), 'f1': np.float64(0.6389456590568237), 'roc_auc': np.float64(0.7614595309600773)}\n",
      "CV Scores for k=3, distance_metric=manhattan: {'accuracy': np.float64(0.8697333333333332), 'precision': np.float64(0.7143662793023134), 'recall': np.float64(0.5921757671919659), 'f1': np.float64(0.6473018694086681), 'roc_auc': np.float64(0.76609122137705)}\n",
      "CV Scores for k=5, distance_metric=euclidean: {'accuracy': np.float64(0.8713333333333333), 'precision': np.float64(0.7303222787313121), 'recall': np.float64(0.5767883738961859), 'f1': np.float64(0.644319427143763), 'roc_auc': np.float64(0.7613632622969415)}\n",
      "CV Scores for k=5, distance_metric=manhattan: {'accuracy': np.float64(0.8698666666666666), 'precision': np.float64(0.7205110777734897), 'recall': np.float64(0.582510770467153), 'f1': np.float64(0.6441596337385755), 'roc_auc': np.float64(0.7626195130477507)}\n",
      "CV Scores for k=7, distance_metric=euclidean: {'accuracy': np.float64(0.8741333333333333), 'precision': np.float64(0.7433283883757301), 'recall': np.float64(0.5769471322172747), 'f1': np.float64(0.6492380356723374), 'roc_auc': np.float64(0.7631933933502533)}\n",
      "CV Scores for k=7, distance_metric=manhattan: {'accuracy': np.float64(0.8750666666666668), 'precision': np.float64(0.7447173237437716), 'recall': np.float64(0.5802470785103421), 'f1': np.float64(0.6520728171404814), 'roc_auc': np.float64(0.7649761856379425)}\n",
      "CV Scores for k=9, distance_metric=euclidean: {'accuracy': np.float64(0.8756), 'precision': np.float64(0.7535482869548751), 'recall': np.float64(0.5725540413174157), 'f1': np.float64(0.6503913888389293), 'roc_auc': np.float64(0.7625071568455981)}\n",
      "CV Scores for k=9, distance_metric=manhattan: {'accuracy': np.float64(0.876), 'precision': np.float64(0.7541112139383198), 'recall': np.float64(0.5747065923903067), 'f1': np.float64(0.6520708384398709), 'roc_auc': np.float64(0.7635396899830911)}\n",
      "CV Scores for k=11, distance_metric=euclidean: {'accuracy': np.float64(0.8766666666666666), 'precision': np.float64(0.756658795797366), 'recall': np.float64(0.5732868049604766), 'f1': np.float64(0.652155106629321), 'roc_auc': np.float64(0.7633263249780167)}\n",
      "CV Scores for k=11, distance_metric=manhattan: {'accuracy': np.float64(0.8769333333333333), 'precision': np.float64(0.7608000001011165), 'recall': np.float64(0.5706134393998237), 'f1': np.float64(0.6517600318843353), 'roc_auc': np.float64(0.7626400902626493)}\n",
      "Best hyperparameters: k=11, distance_metric=manhattan\n",
      "Submission file saved as 'submissions.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess data\n",
    "X, y, X_test = preprocess_data('train.csv', 'test.csv')\n",
    "# print(X.dtypes)\n",
    "# print(y.dtypes)\n",
    "\n",
    "# Hyperparameter tuning (finding the best k and distance metric)\n",
    "best_k = None\n",
    "best_distance_metric = None\n",
    "best_cv_score = -1\n",
    "\n",
    "# Define possible values for hyperparameters\n",
    "k_values = [3, 5, 7, 9, 11]\n",
    "distance_metrics = ['euclidean', 'manhattan']\n",
    "\n",
    "# Try each combination of k and distance metric\n",
    "for k in k_values:\n",
    "    for distance_metric in distance_metrics:\n",
    "        knn = KNN(k=k, distance_metric=distance_metric)\n",
    "        cv_scores = cross_validate(X, y, knn)\n",
    "        print(f\"CV Scores for k={k}, distance_metric={distance_metric}: {cv_scores}\")\n",
    "        \n",
    "        # Check if this is the best model so far\n",
    "        if cv_scores['accuracy'] > best_cv_score:\n",
    "            best_cv_score = cv_scores['accuracy']\n",
    "            best_k = k\n",
    "            best_distance_metric = distance_metric\n",
    "\n",
    "print(f\"Best hyperparameters: k={best_k}, distance_metric={best_distance_metric}\")\n",
    "\n",
    "# Train the final model with the best hyperparameters\n",
    "knn = KNN(k=best_k, distance_metric=best_distance_metric)\n",
    "knn.fit(X, y)\n",
    "\n",
    "# Predict on the test set\n",
    "test_predictions = knn.predict(X_test)\n",
    "\n",
    "# Save the test predictions\n",
    "submission = pd.DataFrame({'id': pd.read_csv('test.csv')['id'], 'Exited': test_predictions})\n",
    "submission.to_csv('submissions.csv', index=False)\n",
    "\n",
    "print(\"Submission file saved as 'submissions.csv'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
