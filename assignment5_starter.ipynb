{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class KNN:\n",
    "    def __init__(self, k=3, distance_metric='euclidean'):\n",
    "        self.k = k\n",
    "        self.distance_metric = distance_metric\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Store the training data as NumPy arrays\n",
    "        self.X_train = np.array(X)\n",
    "        self.y_train = np.array(y, dtype=int)  # Ensure y_train is integer type\n",
    "\n",
    "    def predict(self, X, return_probabilities=True):\n",
    "        # Predict the label or probability for each example in the test set\n",
    "        predictions = [self._predict(x, return_probabilities) for x in np.array(X)]\n",
    "        return np.array(predictions)\n",
    "\n",
    "    def _predict(self, x, return_probabilities):\n",
    "        # Compute the distances between x and all examples in the training set\n",
    "        distances = self.compute_distances(x, self.X_train)\n",
    "        \n",
    "        # Sort by distance and return the indices of the k nearest neighbors\n",
    "        k_indices = np.argsort(distances)[:self.k]\n",
    "        \n",
    "        # Get the labels of the k nearest samples\n",
    "        k_nearest_labels = self.y_train[k_indices]\n",
    "        \n",
    "        if return_probabilities:\n",
    "            # Return the proportion of neighbors that are class 1 as the probability\n",
    "            return np.mean(k_nearest_labels)\n",
    "        else:\n",
    "            # Return the most common class among the k neighbors\n",
    "            return np.bincount(k_nearest_labels).argmax()\n",
    "\n",
    "    def compute_distances(self, x, X_train):\n",
    "        \"\"\" Efficient vectorized distance computation. \"\"\"\n",
    "        if self.distance_metric == 'euclidean':\n",
    "            # Vectorized Euclidean distance computation\n",
    "            return np.sqrt(np.sum((X_train - x) ** 2, axis=1))\n",
    "        elif self.distance_metric == 'manhattan':\n",
    "            # Vectorized Manhattan distance computation\n",
    "            return np.sum(np.abs(X_train - x), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def z_score_scaler(X, mean=None, std=None):\n",
    "    \"\"\" Scale features using z-score normalization. \"\"\"\n",
    "    if mean is None:\n",
    "        mean = np.mean(X, axis=0)\n",
    "    if std is None:\n",
    "        std = np.std(X, axis=0)\n",
    "    return (X - mean) / std, mean, std\n",
    "\n",
    "def one_hot_encode(df, column):\n",
    "    \"\"\" One-hot encode a single categorical column. \"\"\"\n",
    "    dummies = pd.get_dummies(df[column], prefix=column, drop_first=True)\n",
    "    df = pd.concat([df, dummies], axis=1)\n",
    "    df.drop(column, axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "def preprocess_data(train_path, test_path):\n",
    "    \"\"\" Preprocess the train and test datasets according to the task requirements. \"\"\"\n",
    "    \n",
    "    # Load the datasets\n",
    "    train_data = pd.read_csv(train_path)\n",
    "    test_data = pd.read_csv(test_path)\n",
    "    \n",
    "    # Drop irrelevant columns (CustomerId, Surname, id)\n",
    "    train_data = train_data.drop(columns=[\"CustomerId\", \"Surname\", \"id\"])\n",
    "    test_data = test_data.drop(columns=[\"CustomerId\", \"Surname\", \"id\"])\n",
    "    \n",
    "    # Handle missing values for numerical columns (fill with median)\n",
    "    # Selecting only numerical columns for missing value imputation\n",
    "    numeric_columns_train = train_data.select_dtypes(include=[np.number]).columns.drop(\"Exited\")\n",
    "    numeric_columns_test = test_data.select_dtypes(include=[np.number]).columns\n",
    "    \n",
    "    # Fill missing values with median for numeric columns\n",
    "    train_data[numeric_columns_train] = train_data[numeric_columns_train].fillna(train_data[numeric_columns_train].median())\n",
    "    test_data[numeric_columns_test] = test_data[numeric_columns_test].fillna(test_data[numeric_columns_test].median())\n",
    "    \n",
    "    # One-hot encode categorical variables (Geography, Gender) for both train and test data\n",
    "    train_data = one_hot_encode(train_data, \"Geography\")\n",
    "    train_data = one_hot_encode(train_data, \"Gender\")\n",
    "    \n",
    "    test_data = one_hot_encode(test_data, \"Geography\")\n",
    "    test_data = one_hot_encode(test_data, \"Gender\")\n",
    "    \n",
    "    # Align test_data with train_data columns by using column names (excluding 'Exited')\n",
    "    # We don't want to use row indices for reindexing columns, so we use train_data's columns except for 'Exited'.\n",
    "    test_data = test_data.reindex(columns=train_data.drop(columns=[\"Exited\"]).columns, fill_value=0)\n",
    "    \n",
    "    # Separate features (X) and target (y) for training data\n",
    "    X_train = train_data.drop(columns=[\"Exited\"])  # Training features\n",
    "    y_train = train_data[\"Exited\"]\n",
    "    \n",
    "    # Scale the features using z-score normalization (fit on train, transform on both train and test)\n",
    "    X_train_scaled, mean_train, std_train = z_score_scaler(X_train)\n",
    "    X_test_scaled, _, _ = z_score_scaler(test_data, mean_train, std_train)\n",
    "    \n",
    "    return X_train_scaled, y_train, X_test_scaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def accuracy_score_manual(y_true, y_pred):\n",
    "    \"\"\" Manually calculate accuracy. \"\"\"\n",
    "    return np.sum(y_true == y_pred) / len(y_true)\n",
    "\n",
    "def precision_score_manual(y_true, y_pred):\n",
    "    \"\"\" Manually calculate precision. \"\"\"\n",
    "    true_positives = np.sum((y_pred == 1) & (y_true == 1))\n",
    "    predicted_positives = np.sum(y_pred == 1)\n",
    "    if predicted_positives == 0:\n",
    "        return 0\n",
    "    return true_positives / predicted_positives\n",
    "\n",
    "def recall_score_manual(y_true, y_pred):\n",
    "    \"\"\" Manually calculate recall. \"\"\"\n",
    "    true_positives = np.sum((y_pred == 1) & (y_true == 1))\n",
    "    actual_positives = np.sum(y_true == 1)\n",
    "    if actual_positives == 0:\n",
    "        return 0\n",
    "    return true_positives / actual_positives\n",
    "\n",
    "def f1_score_manual(y_true, y_pred):\n",
    "    \"\"\" Manually calculate F1 score. \"\"\"\n",
    "    precision = precision_score_manual(y_true, y_pred)\n",
    "    recall = recall_score_manual(y_true, y_pred)\n",
    "    if (precision + recall) == 0:\n",
    "        return 0\n",
    "    return 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "def roc_auc_score_manual(y_true, y_pred):\n",
    "    \"\"\" Manually calculate ROC AUC score. \"\"\"\n",
    "    # For simplicity, we'll approximate ROC AUC using a basic method:\n",
    "    # Here, we treat it as the proportion of correct rankings of positive vs. negative instances\n",
    "    pos = y_true == 1\n",
    "    neg = y_true == 0\n",
    "    correct_rankings = 0\n",
    "    total_pairs = np.sum(pos) * np.sum(neg)\n",
    "    \n",
    "    if total_pairs == 0:\n",
    "        return 0.5  # No positive or no negative examples\n",
    "\n",
    "    for i in range(len(y_true)):\n",
    "        if pos[i]:\n",
    "            correct_rankings += np.sum(y_pred[i] > y_pred[neg])\n",
    "\n",
    "    return correct_rankings / total_pairs\n",
    "\n",
    "def cross_validate(X, y, knn, n_splits=5):\n",
    "    # Shuffle and split the data into k folds\n",
    "    indices = np.arange(X.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    fold_size = X.shape[0] // n_splits\n",
    "    folds = [indices[i * fold_size: (i + 1) * fold_size] for i in range(n_splits)]\n",
    "    \n",
    "    accuracy_scores = []\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    f1_scores = []\n",
    "    roc_auc_scores = []\n",
    "    \n",
    "    # Cross-validation loop\n",
    "    for i in range(n_splits):\n",
    "        # Create training and validation sets\n",
    "        val_indices = folds[i]\n",
    "        train_indices = np.concatenate([folds[j] for j in range(n_splits) if j != i])\n",
    "        \n",
    "        # Use .iloc[] to access rows by index for DataFrames\n",
    "        X_train, X_val = X.iloc[train_indices], X.iloc[val_indices]\n",
    "        y_train, y_val = y.iloc[train_indices], y.iloc[val_indices]\n",
    "        \n",
    "        # Train the KNN model on the training set\n",
    "        knn.fit(X_train, y_train)\n",
    "        \n",
    "        # Predict on the validation set\n",
    "        y_pred = knn.predict(X_val)\n",
    "        \n",
    "        # Calculate evaluation metrics manually\n",
    "        accuracy_scores.append(accuracy_score_manual(y_val.values, y_pred))\n",
    "        precision_scores.append(precision_score_manual(y_val.values, y_pred))\n",
    "        recall_scores.append(recall_score_manual(y_val.values, y_pred))\n",
    "        f1_scores.append(f1_score_manual(y_val.values, y_pred))\n",
    "        roc_auc_scores.append(roc_auc_score_manual(y_val.values, y_pred))\n",
    "    \n",
    "    # Return the average of each metric across the folds\n",
    "    return {\n",
    "        'accuracy': np.mean(accuracy_scores),\n",
    "        'precision': np.mean(precision_scores),\n",
    "        'recall': np.mean(recall_scores),\n",
    "        'f1': np.mean(f1_scores),\n",
    "        'roc_auc': np.mean(roc_auc_scores)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Scores for k=3, distance_metric=euclidean: {'accuracy': np.float64(0.7056000000000001), 'precision': np.float64(0.8496913972242599), 'recall': np.float64(0.3297503706522909), 'f1': np.float64(0.4747523389600114), 'roc_auc': np.float64(0.743217109751015)}\n",
      "CV Scores for k=3, distance_metric=manhattan: {'accuracy': np.float64(0.701), 'precision': np.float64(0.8440713038774126), 'recall': np.float64(0.31810782987367847), 'f1': np.float64(0.4619691200943059), 'roc_auc': np.float64(0.7495758127917269)}\n",
      "CV Scores for k=5, distance_metric=euclidean: {'accuracy': np.float64(0.6288666666666666), 'precision': np.float64(0.8860359489403414), 'recall': np.float64(0.22536023671600036), 'f1': np.float64(0.359143864430796), 'roc_auc': np.float64(0.804181393663096)}\n",
      "CV Scores for k=5, distance_metric=manhattan: {'accuracy': np.float64(0.6267333333333334), 'precision': np.float64(0.9015719188325313), 'recall': np.float64(0.2157985241114663), 'f1': np.float64(0.3478601284990314), 'roc_auc': np.float64(0.8074508946596314)}\n",
      "CV Scores for k=7, distance_metric=euclidean: {'accuracy': np.float64(0.5728666666666666), 'precision': np.float64(0.9219633027522937), 'recall': np.float64(0.15735154746480298), 'f1': np.float64(0.26873401784055806), 'roc_auc': np.float64(0.8349232305367378)}\n",
      "CV Scores for k=7, distance_metric=manhattan: {'accuracy': np.float64(0.5718), 'precision': np.float64(0.9095804395863551), 'recall': np.float64(0.1447777038525789), 'f1': np.float64(0.24971186896341), 'roc_auc': np.float64(0.835458569423673)}\n",
      "CV Scores for k=9, distance_metric=euclidean: {'accuracy': np.float64(0.5325333333333333), 'precision': np.float64(0.9373126773960605), 'recall': np.float64(0.12189968678737077), 'f1': np.float64(0.21558285555742338), 'roc_auc': np.float64(0.8524634896542761)}\n",
      "CV Scores for k=9, distance_metric=manhattan: {'accuracy': np.float64(0.5279999999999999), 'precision': np.float64(0.9316424937436405), 'recall': np.float64(0.10709262003432793), 'f1': np.float64(0.1920496267542769), 'roc_auc': np.float64(0.8492522425455379)}\n",
      "CV Scores for k=11, distance_metric=euclidean: {'accuracy': np.float64(0.4991333333333333), 'precision': np.float64(0.9536155839381646), 'recall': np.float64(0.09391560143920297), 'f1': np.float64(0.17093450866948695), 'roc_auc': np.float64(0.855587081752715)}\n",
      "CV Scores for k=11, distance_metric=manhattan: {'accuracy': np.float64(0.4917999999999999), 'precision': np.float64(0.9475723270440252), 'recall': np.float64(0.08052662286717936), 'f1': np.float64(0.14789403493440184), 'roc_auc': np.float64(0.8618318752254535)}\n",
      "Best hyperparameters: k=3, distance_metric=euclidean\n",
      "Submission file saved as 'submissions.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess data\n",
    "X, y, X_test = preprocess_data('train.csv', 'test.csv')\n",
    "\n",
    "# Hyperparameter tuning (finding the best k and distance metric)\n",
    "best_k = None\n",
    "best_distance_metric = None\n",
    "best_cv_score = -1\n",
    "\n",
    "# Define possible values for hyperparameters\n",
    "k_values = [3, 5, 7, 9, 11]\n",
    "distance_metrics = ['euclidean', 'manhattan']\n",
    "\n",
    "# Try each combination of k and distance metric\n",
    "for k in k_values:\n",
    "    for distance_metric in distance_metrics:\n",
    "        knn = KNN(k=k, distance_metric=distance_metric)\n",
    "        cv_scores = cross_validate(X, y, knn)\n",
    "        print(f\"CV Scores for k={k}, distance_metric={distance_metric}: {cv_scores}\")\n",
    "        \n",
    "        # Check if this is the best model so far\n",
    "        if cv_scores['accuracy'] > best_cv_score:\n",
    "            best_cv_score = cv_scores['accuracy']\n",
    "            best_k = k\n",
    "            best_distance_metric = distance_metric\n",
    "\n",
    "print(f\"Best hyperparameters: k={best_k}, distance_metric={best_distance_metric}\")\n",
    "\n",
    "# Train the final model with the best hyperparameters\n",
    "knn = KNN(k=best_k, distance_metric=best_distance_metric)\n",
    "knn.fit(X, y)\n",
    "\n",
    "# Predict on the test set\n",
    "test_predictions = knn.predict(X_test)\n",
    "\n",
    "# Save the test predictions\n",
    "submission = pd.DataFrame({'id': pd.read_csv('test.csv')['id'], 'Exited': test_predictions})\n",
    "submission.to_csv('submissions.csv', index=False)\n",
    "\n",
    "print(\"Submission file saved as 'submissions.csv'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
